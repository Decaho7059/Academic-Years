{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Laboratoire 2 de CEG 4536**\n"
      ],
      "metadata": {
        "id": "gkbs1NnAR9vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tache 3"
      ],
      "metadata": {
        "id": "LsPo2vJgn-MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache3_implementation.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Déclaration préalable de reduction_kernel\n",
        "__global__ void reduction_kernel(int *input, int *output, int n);\n",
        "\n",
        "__device__ void nested_reduction(int *output, int grid_size) {\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        reduction_kernel<<<1, grid_size, grid_size * sizeof(int)>>>(output, output, grid_size);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void reduction_kernel(int *input, int *output, int n) {\n",
        "    extern __shared__ int sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    sdata[tid] = (i < n) ? input[i] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
        "\n",
        "    // Appel de la réduction imbriquée si nécessaire\n",
        "    if (blockIdx.x == 0) nested_reduction(output, gridDim.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int n = 1024;\n",
        "    int *h_input, *h_output, *d_input, *d_output;\n",
        "\n",
        "    h_input = (int*)malloc(n * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int));\n",
        "\n",
        "    for (int i = 0; i < n; ++i) h_input[i] = 1;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Démarrer l'événement pour mesurer le temps\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Lancer le kernel\n",
        "    reduction_kernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, n);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Sum of array elements with nested execution: %d\\n\", *h_output);\n",
        "    printf(\"Kernel Execution Time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s9VEhVL1n8-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f3ad79-938c-4932-c43e-cc79a3106b67"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Tache3_implementation.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -dc Tache3_implementation.cu -o Tache3_implementation.o"
      ],
      "metadata": {
        "id": "0rxkTwben8h-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o Tache3_implementation Tache3_implementation.o\n"
      ],
      "metadata": {
        "id": "AN0btICln8Wv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Tache3_implementation"
      ],
      "metadata": {
        "id": "YR7aszE2n8NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de98d1b9-05e3-4785-a457-efcefdabc4c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of array elements with nested execution: 1024\n",
            "Kernel Execution Time: 77.724510 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache3_implementation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKsbXLugNOlv",
        "outputId": "92bc5161-1adf-428a-83e6-843941b8e9a8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==8222== NVPROF is profiling process 8222, command: ./Tache3_implementation\n",
            "Sum of array elements with nested execution: 1024\n",
            "Kernel Execution Time: 82.947037 ms\n",
            "==8222== Profiling application: ./Tache3_implementation\n",
            "==8222== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   91.32%  39.744us         1  39.744us  39.744us  39.744us  reduction_kernel(int*, int*, int)\n",
            "                    5.37%  2.3360us         1  2.3360us  2.3360us  2.3360us  [CUDA memcpy DtoH]\n",
            "                    3.31%  1.4400us         1  1.4400us  1.4400us  1.4400us  [CUDA memcpy HtoD]\n",
            "      API calls:   67.33%  171.73ms         2  85.864ms  4.2580us  171.72ms  cudaMalloc\n",
            "                   26.69%  68.081ms         1  68.081ms  68.081ms  68.081ms  cudaEventSynchronize\n",
            "                    5.83%  14.870ms         1  14.870ms  14.870ms  14.870ms  cudaLaunchKernel\n",
            "                    0.05%  132.59us       114  1.1630us     144ns  52.363us  cuDeviceGetAttribute\n",
            "                    0.05%  120.53us         2  60.262us  12.984us  107.54us  cudaFree\n",
            "                    0.02%  55.861us         2  27.930us  26.607us  29.254us  cudaMemcpy\n",
            "                    0.00%  11.746us         1  11.746us  11.746us  11.746us  cuDeviceGetName\n",
            "                    0.00%  11.672us         2  5.8360us  4.8320us  6.8400us  cudaEventRecord\n",
            "                    0.00%  11.143us         2  5.5710us     782ns  10.361us  cudaEventCreate\n",
            "                    0.00%  5.5230us         1  5.5230us  5.5230us  5.5230us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.5940us         1  4.5940us  4.5940us  4.5940us  cuDeviceTotalMem\n",
            "                    0.00%  3.8920us         1  3.8920us  3.8920us  3.8920us  cudaEventElapsedTime\n",
            "                    0.00%  1.5920us         3     530ns     164ns  1.1000us  cuDeviceGetCount\n",
            "                    0.00%     898ns         2     449ns     194ns     704ns  cuDeviceGet\n",
            "                    0.00%     548ns         1     548ns     548ns     548ns  cuModuleGetLoadingMode\n",
            "                    0.00%     228ns         1     228ns     228ns     228ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implémentation du modèle avec une reduction parallèle sans une execution imbriqué**"
      ],
      "metadata": {
        "id": "KO2xnbJ7n7c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache3_SansExeImbriq.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void reduction_kernel(int *input, int *output, int n) {\n",
        "    extern __shared__ int sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    sdata[tid] = (i < n) ? input[i] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int n = 1024;\n",
        "    int *h_input, *h_output, *d_input, *d_output;\n",
        "\n",
        "    h_input = (int*)malloc(n * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int) * ((n + 255) / 256));  // pour les résultats intermédiaires\n",
        "\n",
        "    for (int i = 0; i < n; ++i) h_input[i] = 1;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, sizeof(int) * ((n + 255) / 256));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduction_kernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, n);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Copier les résultats intermédiaires vers l'hôte\n",
        "    cudaMemcpy(h_output, d_output, sizeof(int) * blocksPerGrid, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Réduction finale sur le CPU\n",
        "    int total_sum = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; ++i) {\n",
        "        total_sum += h_output[i];\n",
        "    }\n",
        "\n",
        "    printf(\"Sum of array elements without nested execution: %d\\n\", total_sum);\n",
        "    printf(\"Kernel Execution Time without nested execution: %f ms\\n\", milliseconds);\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7JsBoRWNufn",
        "outputId": "9099e6d3-6186-4c89-cab0-a29bbf312850"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Tache3_SansExeImbriq.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Tache3_SansExeImbriq.cu -o Tache3_SansExeImbriq\n"
      ],
      "metadata": {
        "id": "39zEcHYpN7vV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Tache3_SansExeImbriq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEhH3d72N8eb",
        "outputId": "f8335398-43c0-4d55-8a54-677fc24f4ba5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of array elements without nested execution: 1024\n",
            "Kernel Execution Time without nested execution: 0.229792 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache3_SansExeImbriq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-5A_scEN-6m",
        "outputId": "6177abda-07f8-4188-d10b-2628ccbcf82c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==8357== NVPROF is profiling process 8357, command: ./Tache3_SansExeImbriq\n",
            "Sum of array elements without nested execution: 1024\n",
            "Kernel Execution Time without nested execution: 0.174976 ms\n",
            "==8357== Profiling application: ./Tache3_SansExeImbriq\n",
            "==8357== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   59.09%  4.9910us         1  4.9910us  4.9910us  4.9910us  reduction_kernel(int*, int*, int)\n",
            "                   24.25%  2.0480us         1  2.0480us  2.0480us  2.0480us  [CUDA memcpy DtoH]\n",
            "                   16.67%  1.4080us         1  1.4080us  1.4080us  1.4080us  [CUDA memcpy HtoD]\n",
            "      API calls:   99.69%  180.84ms         2  90.418ms  4.0340us  180.83ms  cudaMalloc\n",
            "                    0.10%  184.06us       114  1.6140us     137ns  94.302us  cuDeviceGetAttribute\n",
            "                    0.09%  167.75us         1  167.75us  167.75us  167.75us  cudaLaunchKernel\n",
            "                    0.06%  101.26us         2  50.630us  7.4390us  93.822us  cudaFree\n",
            "                    0.03%  56.658us         2  28.329us  18.859us  37.799us  cudaMemcpy\n",
            "                    0.01%  17.152us         2  8.5760us  3.7070us  13.445us  cudaEventCreate\n",
            "                    0.01%  11.499us         1  11.499us  11.499us  11.499us  cuDeviceGetName\n",
            "                    0.01%  10.096us         2  5.0480us  3.3860us  6.7100us  cudaEventRecord\n",
            "                    0.00%  6.8040us         1  6.8040us  6.8040us  6.8040us  cudaEventSynchronize\n",
            "                    0.00%  5.4680us         1  5.4680us  5.4680us  5.4680us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.1450us         1  4.1450us  4.1450us  4.1450us  cuDeviceTotalMem\n",
            "                    0.00%  1.7110us         1  1.7110us  1.7110us  1.7110us  cudaEventElapsedTime\n",
            "                    0.00%  1.3770us         3     459ns     202ns     920ns  cuDeviceGetCount\n",
            "                    0.00%  1.0330us         2     516ns     211ns     822ns  cuDeviceGet\n",
            "                    0.00%     492ns         1     492ns     492ns     492ns  cuModuleGetLoadingMode\n",
            "                    0.00%     352ns         1     352ns     352ns     352ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observation**\n",
        "L'exécution imbriquée des kernels entraîne une surcharge significative, ce qui ralentit le traitement pour les petites tailles de tableau, comme 1024. Sans exécution imbriquée, le kernel s'exécute efficacement en 4.96 µs, alors qu'avec exécution imbriquée, il faut environ 39.615 µs, principalement en raison de la gestion et de la synchronisation des kernels.\n",
        "Les appels API, notamment **cudaEventSynchronize** et **cudaMalloc**, consomment aussi plus de temps avec l'exécution imbriquée. Bien que cela soit inefficace pour les petits tableaux, cette approche pourrait être bénéfique pour de grandes tailles de tableau, permettant d'exploiter un parallélisme accru."
      ],
      "metadata": {
        "id": "Gyl5XNWXPXgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implémentation du modèle avec une reduction parallèle en utilisant un tableau de plus grande taille**\n",
        "\n",
        "**soit la taille d'élément n = 33687"
      ],
      "metadata": {
        "id": "5dM9rnrhPznE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache3_Tab_de_grande_taille.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Déclaration préalable de reduction_kernel\n",
        "__global__ void reduction_kernel(int *input, int *output, int n);\n",
        "\n",
        "__device__ void nested_reduction(int *output, int grid_size) {\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        reduction_kernel<<<1, grid_size, grid_size * sizeof(int)>>>(output, output, grid_size);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void reduction_kernel(int *input, int *output, int n) {\n",
        "    extern __shared__ int sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    sdata[tid] = (i < n) ? input[i] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
        "\n",
        "    // Appel de la réduction imbriquée si nécessaire\n",
        "    if (blockIdx.x == 0) nested_reduction(output, gridDim.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int n = 33687;\n",
        "    int *h_input, *h_output, *d_input, *d_output;\n",
        "\n",
        "    h_input = (int*)malloc(n * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int));\n",
        "\n",
        "    for (int i = 0; i < n; ++i) h_input[i] = 1;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Démarrer l'événement pour mesurer le temps\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Lancer le kernel\n",
        "    reduction_kernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, n);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Sum of array elements with nested execution: %d\\n\", *h_output);\n",
        "    printf(\"Kernel Execution Time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXvFJw-hQSPu",
        "outputId": "ee57a06d-fa71-48ec-ffec-150b5d425619"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Tache3_Tab_de_grande_taille.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -dc Tache3_Tab_de_grande_taille.cu -o Tache3_Tab_de_grande_taille.o"
      ],
      "metadata": {
        "id": "TazsgAeCQh5W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o Tache3_Tab_de_grande_taille Tache3_Tab_de_grande_taille.o"
      ],
      "metadata": {
        "id": "RiAN7kp4Qin8"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Tache3_Tab_de_grande_taille"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfA6ciKcQmIZ",
        "outputId": "c9bc0c6a-36d4-480d-c9ea-919719d9099e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of array elements with nested execution: 32768\n",
            "Kernel Execution Time: 78.051933 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache3_Tab_de_grande_taille"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcA7ofvvQn3M",
        "outputId": "99d56b4b-7d67-464e-934c-e304392cf68c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==11017== NVPROF is profiling process 11017, command: ./Tache3_Tab_de_grande_taille\n",
            "Sum of array elements with nested execution: 32768\n",
            "Kernel Execution Time: 81.197601 ms\n",
            "==11017== Profiling application: ./Tache3_Tab_de_grande_taille\n",
            "==11017== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   72.15%  40.959us         1  40.959us  40.959us  40.959us  reduction_kernel(int*, int*, int)\n",
            "                   24.24%  13.760us         1  13.760us  13.760us  13.760us  [CUDA memcpy HtoD]\n",
            "                    3.61%  2.0480us         1  2.0480us  2.0480us  2.0480us  [CUDA memcpy DtoH]\n",
            "      API calls:   68.99%  181.59ms         2  90.797ms  4.9870us  181.59ms  cudaMalloc\n",
            "                   25.81%  67.938ms         1  67.938ms  67.938ms  67.938ms  cudaEventSynchronize\n",
            "                    5.04%  13.263ms         1  13.263ms  13.263ms  13.263ms  cudaLaunchKernel\n",
            "                    0.06%  163.33us         2  81.666us  16.726us  146.61us  cudaFree\n",
            "                    0.05%  129.17us       114  1.1330us     138ns  51.282us  cuDeviceGetAttribute\n",
            "                    0.03%  85.508us         2  42.754us  32.237us  53.271us  cudaMemcpy\n",
            "                    0.00%  12.445us         2  6.2220us  5.3380us  7.1070us  cudaEventRecord\n",
            "                    0.00%  11.533us         2  5.7660us     728ns  10.805us  cudaEventCreate\n",
            "                    0.00%  11.211us         1  11.211us  11.211us  11.211us  cuDeviceGetName\n",
            "                    0.00%  5.2280us         1  5.2280us  5.2280us  5.2280us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.6060us         1  4.6060us  4.6060us  4.6060us  cuDeviceTotalMem\n",
            "                    0.00%  4.4960us         1  4.4960us  4.4960us  4.4960us  cudaEventElapsedTime\n",
            "                    0.00%  1.3550us         3     451ns     210ns     879ns  cuDeviceGetCount\n",
            "                    0.00%     899ns         2     449ns     183ns     716ns  cuDeviceGet\n",
            "                    0.00%     576ns         1     576ns     576ns     576ns  cuModuleGetLoadingMode\n",
            "                    0.00%     234ns         1     234ns     234ns     234ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implémentation du modèle avec une reduction parallèle en utilisant un tableau de plus grande taille* sans execution imbriquee*\n"
      ],
      "metadata": {
        "id": "2o6vkJA-RBa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache3_TabDeGrandeTaille_SansExeImbriq.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void reduction_kernel(int *input, int *output, int n) {\n",
        "    extern __shared__ int sdata[];\n",
        "    int tid = threadIdx.x;\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    sdata[tid] = (i < n) ? input[i] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int n = 33687;\n",
        "    int *h_input, *h_output, *d_input, *d_output;\n",
        "\n",
        "    h_input = (int*)malloc(n * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int) * ((n + 255) / 256));  // pour les résultats intermédiaires\n",
        "\n",
        "    for (int i = 0; i < n; ++i) h_input[i] = 1;\n",
        "\n",
        "    cudaMalloc((void**)&d_input, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_output, sizeof(int) * ((n + 255) / 256));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    reduction_kernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, n);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Copier les résultats intermédiaires vers l'hôte\n",
        "    cudaMemcpy(h_output, d_output, sizeof(int) * blocksPerGrid, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Réduction finale sur le CPU\n",
        "    int total_sum = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; ++i) {\n",
        "        total_sum += h_output[i];\n",
        "    }\n",
        "\n",
        "    printf(\"Sum of array elements without nested execution: %d\\n\", total_sum);\n",
        "    printf(\"Kernel Execution Time without nested execution: %f ms\\n\", milliseconds);\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOZQUkozRIQ9",
        "outputId": "e5dae835-b9f5-4d16-c85f-47bc77100524"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Tache3_TabDeGrandeTaille_SansExeImbriq.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Tache3_TabDeGrandeTaille_SansExeImbriq.cu -o Tache3_TabDeGrandeTaille_SansExeImbriq"
      ],
      "metadata": {
        "id": "5UPOlh2iRMBL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Tache3_TabDeGrandeTaille_SansExeImbriq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ2zYDFNROcd",
        "outputId": "65c75b17-0bc9-4417-aff4-8e886d7e5795"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of array elements without nested execution: 33687\n",
            "Kernel Execution Time without nested execution: 0.168896 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache3_TabDeGrandeTaille_SansExeImbriq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I7Ntj5KRSYO",
        "outputId": "57b86115-ff4d-4a08-deb0-bb770f625012"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==11158== NVPROF is profiling process 11158, command: ./Tache3_TabDeGrandeTaille_SansExeImbriq\n",
            "Sum of array elements without nested execution: 33687\n",
            "Kernel Execution Time without nested execution: 0.178848 ms\n",
            "==11158== Profiling application: ./Tache3_TabDeGrandeTaille_SansExeImbriq\n",
            "==11158== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   60.39%  13.952us         1  13.952us  13.952us  13.952us  [CUDA memcpy HtoD]\n",
            "                   30.61%  7.0720us         1  7.0720us  7.0720us  7.0720us  reduction_kernel(int*, int*, int)\n",
            "                    9.01%  2.0810us         1  2.0810us  2.0810us  2.0810us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.72%  192.16ms         2  96.082ms  4.7930us  192.16ms  cudaMalloc\n",
            "                    0.09%  168.56us         1  168.56us  168.56us  168.56us  cudaLaunchKernel\n",
            "                    0.07%  139.17us       114  1.2200us     131ns  52.745us  cuDeviceGetAttribute\n",
            "                    0.05%  104.49us         2  52.246us  11.344us  93.148us  cudaFree\n",
            "                    0.04%  72.004us         2  36.002us  19.094us  52.910us  cudaMemcpy\n",
            "                    0.01%  13.683us         2  6.8410us  3.1210us  10.562us  cudaEventCreate\n",
            "                    0.01%  12.480us         1  12.480us  12.480us  12.480us  cuDeviceGetName\n",
            "                    0.01%  11.061us         2  5.5300us  3.3380us  7.7230us  cudaEventRecord\n",
            "                    0.00%  8.7010us         1  8.7010us  8.7010us  8.7010us  cudaEventSynchronize\n",
            "                    0.00%  4.9120us         1  4.9120us  4.9120us  4.9120us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.6280us         1  4.6280us  4.6280us  4.6280us  cuDeviceTotalMem\n",
            "                    0.00%  1.8120us         1  1.8120us  1.8120us  1.8120us  cudaEventElapsedTime\n",
            "                    0.00%  1.5110us         3     503ns     194ns     941ns  cuDeviceGetCount\n",
            "                    0.00%  1.1540us         2     577ns     303ns     851ns  cuDeviceGet\n",
            "                    0.00%     492ns         1     492ns     492ns     492ns  cuModuleGetLoadingMode\n",
            "                    0.00%     245ns         1     245ns     245ns     245ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observation et resultats**\n",
        "\n",
        "L'exécution imbriquée des kernels entraîne une surcharge importante, avec un temps d'exécution nettement supérieur pour les petites tailles de tableau, comme 1024, par rapport à la version sans exécution imbriquée. Cette surcharge est principalement due aux besoins accrus en synchronisation et gestion des appels de kernels. Bien que l'exécution imbriquée permette un parallélisme supplémentaire, elle n’est pas avantageuse pour les petites tailles de tableau et pourrait n'être justifiée que pour des tailles beaucoup plus grandes, où elle compenserait les frais de gestion."
      ],
      "metadata": {
        "id": "XFfg4xhpUCRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tache 4"
      ],
      "metadata": {
        "id": "9Thrzgsvn1vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXkJtOEl7M7-",
        "outputId": "e0dac4a2-ad5e-4d15-8249-a52d873188ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  5 05:32:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5uW4f4O7RBC",
        "outputId": "8db9490b-71db-4960-bae4-a0805addc584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [59.5 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,107 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,605 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,389 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,437 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,162 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,310 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,451 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,667 kB]\n",
            "Fetched 23.6 MB in 3s (9,248 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Partie 1** :  Profiling"
      ],
      "metadata": {
        "id": "ZRP_mRecHlmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache4_Optimisation1.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void optimizewithKernel(int *input, int *output, int size) {\n",
        "    extern __shared__ int sharedData[];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Charge les éléments dans la mémoire partagée\n",
        "    if (idx < size) {\n",
        "        sharedData[tid] = input[idx];\n",
        "    } else {\n",
        "        sharedData[tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Réduction parallèle\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sharedData[tid] += sharedData[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Le premier thread de chaque bloc stocke le résultat\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sharedData[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int size = 1024;\n",
        "    int *h_input, *h_output, *d_in, *d_out;\n",
        "    h_input = (int*)malloc(size * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int));\n",
        "\n",
        "    // Initialisation des données\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        h_input[i] = 1;\n",
        "    }\n",
        "\n",
        "    // Allocation de la mémoire sur le GPU\n",
        "    cudaMalloc(&d_in, size * sizeof(int));\n",
        "    cudaMalloc(&d_out, sizeof(int));\n",
        "\n",
        "    // Copie des données de l'hôte vers le GPU\n",
        "    cudaMemcpy(d_in, h_input, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lancer le kernel\n",
        "    optimizewithKernel<<<4, 256, 256 * sizeof(int)>>>(d_in, d_out, size);\n",
        "\n",
        "    // Copie du résultat du GPU vers l'hôte\n",
        "    cudaMemcpy(h_output, d_out, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Affichage du résultat\n",
        "    printf(\"Sum: %d\\n\", *h_output);\n",
        "\n",
        "    // Libération de la mémoire\n",
        "    cudaFree(d_in);\n",
        "    cudaFree(d_out);\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OJ6AxN3He7M",
        "outputId": "fdc94a0b-295b-413f-eef4-2cc7424fbd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Tache4_Optimisation1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Tache4_Optimisation1.cu -o Tache4_Optimisation1"
      ],
      "metadata": {
        "id": "2uXg7iJDKGWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache4_Optimisation1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cYmV503KIz6",
        "outputId": "87317203-5323-4351-88ea-cea80e890991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1750== NVPROF is profiling process 1750, command: ./Tache4_Optimisation1\n",
            "Sum: 256\n",
            "==1750== Profiling application: ./Tache4_Optimisation1\n",
            "==1750== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   58.43%  4.9920us         1  4.9920us  4.9920us  4.9920us  optimizewithKernel(int*, int*, int)\n",
            "                   25.09%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
            "                   16.48%  1.4080us         1  1.4080us  1.4080us  1.4080us  [CUDA memcpy HtoD]\n",
            "      API calls:   50.88%  117.17ms         1  117.17ms  117.17ms  117.17ms  cudaLaunchKernel\n",
            "                   48.95%  112.72ms         2  56.361ms  4.7850us  112.72ms  cudaMalloc\n",
            "                    0.07%  159.46us         2  79.729us  14.392us  145.07us  cudaFree\n",
            "                    0.06%  137.57us       114  1.2060us     145ns  55.073us  cuDeviceGetAttribute\n",
            "                    0.02%  51.727us         2  25.863us  21.225us  30.502us  cudaMemcpy\n",
            "                    0.00%  11.053us         1  11.053us  11.053us  11.053us  cuDeviceGetName\n",
            "                    0.00%  6.2390us         1  6.2390us  6.2390us  6.2390us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.5380us         1  3.5380us  3.5380us  3.5380us  cuDeviceTotalMem\n",
            "                    0.00%  1.2620us         3     420ns     192ns     874ns  cuDeviceGetCount\n",
            "                    0.00%     951ns         2     475ns     194ns     757ns  cuDeviceGet\n",
            "                    0.00%     509ns         1     509ns     509ns     509ns  cuModuleGetLoadingMode\n",
            "                    0.00%     232ns         1     232ns     232ns     232ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7T9OkEykULdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "813ChzF9UK5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Partie 2** : Optimisation pour maximiser l'occupation des warps et minimiser les latences"
      ],
      "metadata": {
        "id": "95mUCcs5Kkxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Tache4_maximisation.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void optimizedKernelLatency(int *input, int *output, int size) {\n",
        "    extern __shared__ int sharedData[];\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < size) {\n",
        "        sharedData[tid] = input[idx];\n",
        "    } else {\n",
        "        sharedData[tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sharedData[tid] += sharedData[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        output[blockIdx.x] = sharedData[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int size = 1024;\n",
        "    int *h_input, *h_output, *d_input, *d_output;\n",
        "\n",
        "    h_input = (int*)malloc(size * sizeof(int));\n",
        "    h_output = (int*)malloc(sizeof(int));\n",
        "\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        h_input[i] = 1;\n",
        "    }\n",
        "\n",
        "    cudaMalloc(&d_input, size * sizeof(int));\n",
        "    cudaMalloc(&d_output, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 128; // Ajustement de la taille pour maximiser l'occupation\n",
        "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    optimizedKernelLatency<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, size);\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Sum: %d\\n\", *h_output);\n",
        "\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePFC0oIXK-uK",
        "outputId": "0f1af027-216e-4a32-8384-819411156374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Tache4_maximisation.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc Tache4_maximisation.cu -o Tache4_maximisation"
      ],
      "metadata": {
        "id": "qD50G-cTK-9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Tache4_maximisation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4QMAxukRRGj",
        "outputId": "17cb6996-3d62-4d48-84dc-92557f56c630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2589== NVPROF is profiling process 2589, command: ./Tache4_maximisation\n",
            "Sum: 128\n",
            "==2589== Profiling application: ./Tache4_maximisation\n",
            "==2589== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   56.52%  4.5760us         1  4.5760us  4.5760us  4.5760us  optimizedKernelLatency(int*, int*, int)\n",
            "                   26.09%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
            "                   17.39%  1.4080us         1  1.4080us  1.4080us  1.4080us  [CUDA memcpy HtoD]\n",
            "      API calls:   71.06%  95.842ms         2  47.921ms  3.9480us  95.838ms  cudaMalloc\n",
            "                   28.67%  38.672ms         1  38.672ms  38.672ms  38.672ms  cudaLaunchKernel\n",
            "                    0.10%  138.57us       114  1.2150us     137ns  54.853us  cuDeviceGetAttribute\n",
            "                    0.10%  130.79us         2  65.396us  11.281us  119.51us  cudaFree\n",
            "                    0.05%  66.977us         2  33.488us  25.398us  41.579us  cudaMemcpy\n",
            "                    0.01%  10.712us         1  10.712us  10.712us  10.712us  cuDeviceGetName\n",
            "                    0.00%  5.6170us         1  5.6170us  5.6170us  5.6170us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.3230us         1  4.3230us  4.3230us  4.3230us  cuDeviceTotalMem\n",
            "                    0.00%  1.8670us         3     622ns     225ns  1.2040us  cuDeviceGetCount\n",
            "                    0.00%  1.3200us         2     660ns     279ns  1.0410us  cuDeviceGet\n",
            "                    0.00%     460ns         1     460ns     460ns     460ns  cuModuleGetLoadingMode\n",
            "                    0.00%     258ns         1     258ns     258ns     258ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SqGlXiLsHSgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nous pouvons souligner a partir de cette tache 🇰\n",
        "\n",
        "**Analyse des Résultats et Documentation** :  L'utilisation de nvprof a révélé des différences notables entre la version initiale et la version optimisée du kernel. Le temps total d'exécution sur le GPU est passé de 4.9600 µs dans la version de base à 4.5760 µs dans la version optimisée, montrant une gestion plus efficace des opérations. De plus, le temps pour cudaMalloc a été réduit de 129.19 ms à 99.406 ms, soulignant une meilleure allocation de la mémoire. L'ajustement de la taille des blocs et l'optimisation de l'occupation des warps ont contribué à diminuer la latence sans affecter les transferts de données (cudaMemcpy).\n",
        "\n",
        "***Rapport d'Amélioration L'optimisation a permis plusieurs avancées ***: un temps de calcul réduit et une meilleure répartition des charges ont amélioré l'exécution du kernel. L'alignement des tailles de blocs sur la taille du warp a maximisé l'occupation et réduit les cycles inactifs, augmentant l'efficacité globale. L'utilisation de la mémoire partagée et la synchronisation des threads ont renforcé la scalabilité, permettant au programme de gérer de plus grandes quantités de données sans dégrader les performances.\n"
      ],
      "metadata": {
        "id": "eQXsxsvpTjLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Pour conclure* on peut souligner que : *texte en italique*\n",
        "\n",
        "**Pour le Profiling de la 1ere optimisation** : L'utilisation du profiling a permis d'identifier les goulets d'étranglement et d'évaluer les performances pour optimiser le programme.\n",
        "\n",
        "**le profiling a partir d'une Optimisation basée sur les profil**s : Les techniques appliquées ont maximisé l'occupation des warps et réduit la latence, améliorant l'efficacité et la scalabilité pour des traitements intensifs sur GPU."
      ],
      "metadata": {
        "id": "8DK95LXvTkFS"
      }
    }
  ]
}